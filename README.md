# ë”¥ëŸ¬ë‹ ê¸°ë°˜ í…ìŠ¤íŠ¸ì˜ ê°ì • ë¶„ì„
Members : 

ì´ê°€ë¹ˆ, í™”í•™ê³¼, gabin0713@hanyang.ac.kr

ì¥ìˆ˜ë¹ˆ, ìˆ˜í•™ê³¼,

ë°•ìŠ¹í˜„, ê²½ì˜í•™ë¶€, boyojeck@hanyang.ac.kr

ì´ìƒë°±, ê¸°ê³„ê³µí•™ë¶€, leesangbaek98@naver.com



ğŸ” ëª©ì°¨
1. Proposal
2. DataSets
3. Methodology
4. Evaluation & Analysis
5. Conclusion-discussion
6. Related Works

-------------------------
# I.Proposal
- Why are you doing this?

ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ê°ì • ì¸ì‹ ê¸°ìˆ ì€ ìš°ë¦¬ê°€ ë¯¸ì²˜ ì•Œì§€ ëª»í–ˆë˜ ì¸ê°„ì˜ ê°ì • íŒ¨í„´ê³¼ ì‹¬ë¦¬ ìƒíƒœë¥¼ ë” ê¹Šì´ ì´í•´í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ì´ëŸ¬í•œ ê°ì • ë¶„ë¥˜ ì‹œìŠ¤í…œì„ í†µí•´ ê°œì¸ì ì¸ ì¸¡ë©´ìœ¼ë¡œëŠ” ì‚¬ëŒë“¤ì˜ ì˜¨ë¼ì¸ í™œë™ê³¼ ì†Œì…œ ë¯¸ë””ì–´ ê²Œì‹œë¬¼ì—ì„œ ê°ì •ì„ ë¶„ì„í•˜ì—¬ ìš°ìš¸ì¦, ë¶ˆì•ˆ, ìŠ¤íŠ¸ë ˆìŠ¤ ë“±ìœ¼ ì •ì‹  ê±´ê°• ë¬¸ì œë¥¼ ì¡°ê¸°ì— ë°œê²¬ ê°€ëŠ¥í•˜ê²Œ í•´ì¤€ë‹¤. ë˜í•œ, ì¸ê³µì§€ëŠ¥ ë¹„ì„œë‚˜ êµìœ¡ìš© ë¡œë´‡ ë“±ì„ í†µí•´ í•™ì—…ì ìœ¼ë¡œë‚˜ ì‚¬ë¬´ì ì¸ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”ì‹œí‚¤ê³ , ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš©(HCI)ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤. ì‚¬íšŒì ì¸ ì¸¡ë©´ìœ¼ë¡œëŠ” ê¸°ì—…ë“¤ì´ ê³ ê° ì„œë¹„ìŠ¤ì—ì„œ ê°ì • ì¸ì‹ ê¸°ìˆ ì„ í†µí•´ ê³ ê°ì˜ ê°ì • ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•…í•˜ì—¬, í”¼ë“œë°± ìˆ˜ìš©ì´ ìš©ì´í•˜ë‹¤. ì†Œì…œ ë¯¸ë””ì–´ì—ì„œ ë°œìƒí•˜ëŠ” í˜ì˜¤ ë°œì–¸ì´ë‚˜ ì‚¬ì´ë²„ ë¶ˆë§ì„ ê°ì§€í•˜ì—¬, ì´ë¥¼ ì‚¬ì „ì— ë°©ì§€í•¨ìœ¼ë¡œì¨ ì‚¬íšŒì  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ìˆ˜ë‹¨ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤. ê²°ë¡ ì ìœ¼ë¡œ, ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ê°ì • ì¸ì‹ ì—°êµ¬ëŠ” ë‹¤ì–‘í•œ ì‚¬íšŒì , í•™ë¬¸ì , ê²½ì œì  ì´ì ì„ ì œê³µí•˜ë©°, ì¸ë¥˜ì˜ ì‚¶ì„ ë” ë‚˜ì€ ë°©í–¥ìœ¼ë¡œ ì´ëŒì–´ê°ˆ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ë¥¼ ì§€ì†í•˜ê³  ë°œì „ì‹œí‚¤ëŠ” ê²ƒì€ ìš°ë¦¬ì˜ ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¤ê³ , ë” ë‚˜ì€ ì‚¬íšŒë¥¼ ë§Œë“œëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒì´ë¼ íŒë‹¨í•˜ì—¬ ì„ ì •í•˜ê²Œ ë˜ì—ˆë‹¤.

- What do you want to see at the end?

ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê°ì • ì¸ì‹ ê¸°ìˆ ì„ í†µí•´ ì •ì‹  ê±´ê°• ê´€ë¦¬, ê³ ê° ì„œë¹„ìŠ¤, ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš©, ì‚¬íšŒì  ë¬¸ì œ í•´ê²° ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‹¤ì§ˆì ì¸ ë³€í™”ë¥¼ ì´ë£¨ê³ ì í•œë‹¤. ì´ ê¸°ìˆ ì€ ì‚¬ëŒë“¤ì˜ ì˜¨ë¼ì¸ í™œë™ê³¼ ì†Œì…œ ë¯¸ë””ì–´ ê²Œì‹œë¬¼ì—ì„œ ê°ì •ì„ ë¶„ì„í•˜ì—¬ ìš°ìš¸ì¦, ë¶ˆì•ˆ, ìŠ¤íŠ¸ë ˆìŠ¤ ë“±ì˜ ë¬¸ì œë¥¼ ì¡°ê¸°ì— ë°œê²¬í•˜ê³  ì˜ˆë°©í•˜ë©°, ê³ ê°ì˜ ê°ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì•…í•˜ì—¬ ë” ë‚˜ì€ ì„œë¹„ìŠ¤ì™€ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤. ë˜í•œ, í˜ì˜¤ ë°œì–¸ì´ë‚˜ ì‚¬ì´ë²„ ë¶ˆë§ì„ ê°ì§€í•˜ì—¬ ì•ˆì „í•œ ì¸í„°ë„· í™˜ê²½ì„ ì¡°ì„±í•˜ê³ , ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬íšŒì  íŠ¸ë Œë“œì™€ ê°ì • ë³€í™”ë¥¼ íŒŒì•…í•¨ìœ¼ë¡œì¨ íš¨ê³¼ì ì¸ ì •ì±… ìˆ˜ë¦½ì„ ì§€ì›í•œë‹¤. ê¶ê·¹ì ìœ¼ë¡œ, ì´ ì—°êµ¬ë¥¼ í†µí•´ ì¸ê°„ ê°ì •ì˜ ë³µì¡ì„±ì„ ì´í•´í•˜ê³  ë‹¤ì–‘í•œ í•™ë¬¸ ë¶„ì•¼ì—ì„œ ìƒˆë¡œìš´ ì´ë¡ ê³¼ ì‹¤ì²œ ë°©ì•ˆì„ ê°œë°œí•˜ë©°, ì˜ˆìˆ ê³¼ ë¬¸í™” ì—°êµ¬ ë“±ì—ì„œë„ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆê¸°ë¥¼ ê¸°ëŒ€í•œë‹¤. ì´ë¥¼ ìœ„í•´, ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ë˜ì˜ ê°ì •ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ì—¬, ì‚¬ëŒë“¤ì´ ë” ë‚˜ì€ ì˜ì‚¬ê²°ì •ì„ í•  ìˆ˜ ìˆë„ë¡ ë•ê³ ì í•˜ëŠ” ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ê³ ì í•œë‹¤.

-------------------------
# II.DataSets
ì»¤ë®¤ë‹ˆí‹° ê¸°ë°˜ì˜ ë…ë¦½ ì—°êµ¬ì†Œì¸ DAIR.AIì—ì„œ ì œê³µí•˜ëŠ” 'Emotion Dataset'ì„ ì´ìš©í•œë‹¤.

í•´ë‹¹ ë°ì´í„°ëŠ” twitter APIë¥¼ í†µí•´ ìˆ˜ì§‘ëœ ì˜ì–´ë¬¸ì¥ì„ ì—¬ì„¯ê°€ì§€ ê¸°ë³¸ê°ì •ë“¤(anger, fear, joy, love, sadness, surprise)ë¡œ ë¶„ë¥˜ë˜ì—ˆë‹¤.

ì„ í–‰ ì—°êµ¬ì¸ â€˜CARER: Contextualized Affect Representations for Emotion Recognitionâ€™ì˜ ì ‘ê·¼ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ê°€ ê°€ê³µì²˜ë¦¬ ëœë‹¤.

Prior research Link : <https://aclanthology.org/D18-1404.pdf>  

Data link : <https://github.com/dair-ai/emotion_dataset>

## DataSets info

'Emotion Dataset' ì¤‘ í•™ìŠµì„ ìœ„í•´ ì œê³µí•œ split dataë¥¼ ì‚¬ìš©í•œë‹¤.

![ë°ì´í„°íŒŒì¼](https://github.com/subineda01/HY-AI-x-DeepLearnig/blob/main/image/dataset.png)

train.csv(16,000), validation.csv(2,000), test.csv(2,000)
-> ì´ 20,000ê°œì˜ ë°ì´í„° (1968KB)


## Data example
```sh
"text" : "im feeling quite sad and sorry for myself but ill snap out of it soon",
"label": 0
```

## Features
- text : í•œ ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ string í˜•íƒœì˜ feature
- label : ê°ì •ì„ ë¶„ë¥˜í•œ ë¼ë²¨ë¡œ int í˜•íƒœì˜ feature, 6ê°€ì§€ ìƒíƒœë¥¼ í‘œí˜„

| Emotion | label |
| ------- | ------- |
| sadness | 0 |
| joy | 1 |
| love | 2 |
| anger | 3 |
| fear | 4 |
| surprise | 5 |



-----------------------
# III.Methodology
## 1. Lstm classification
    
ë¬¸ì¥ê³¼ ê°™ì€ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” ì£¼ë¡œ RNN(ìˆœí™˜ì‹ ê²½ë§, Recurrent Neural Network)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 
  
ë¬¸ì¥ ì† ì´ì „ ë‹¨ì–´ì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ëŠ” ê²ƒì„ ì‹œì‘ìœ¼ë¡œ, ë‹¤ìŒì˜ ìƒˆë¡œìš´ ë‹¨ì–´ì™€ì˜ ì •ë³´ë¥¼ í•©ì³ì„œ ì²˜ë¦¬í•˜ë©´ì„œ AIëŠ” ë‹¨ì–´ì˜ ìˆœì„œì™€ ë¬¸ë§¥ì„ ì´í•´í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

ì´ì „ì˜ ë…¸ë“œì—ì„œ ë‚˜ì˜¨ í•œê°œì˜ ì •ë³´ì™€ ìƒˆë¡œìš´ ë‹¨ì–´ì˜ ì •ë³´ë§Œì„ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì—, ê¸´ ë¬¸ì¥ì— ëŒ€í•˜ì—¬ ì²˜ë¦¬í•  ë•Œ ì•ì˜ ì •ë³´ë¥¼ ì˜ ê¸°ì–µí•˜ì§€ ëª»í•  ìˆ˜ ìˆëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.
    
ì „í†µì ì¸ RNNì˜ ë‹¨ì ì„ ë³´ì™„í•œ RNNì˜ ì¼ì¢…ì„ LSTM(ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬, Long Short-Term Memory)ë¼ê³  í•©ë‹ˆë‹¤. 
  
í•´ë‹¹ ëª¨ë¸ì€ ë©”ëª¨ë¦¬ ì…€ì— ì…ë ¥ ê²Œì´íŠ¸, ë§ê° ê²Œì´íŠ¸, ì¶œë ¥ ê²Œì´íŠ¸ë¥¼ ì¶”ê°€í•˜ì—¬ ë¶ˆí•„ìš”í•œ ê¸°ì–µì„ ì§€ìš°ê³ , ê¸°ì–µí•  ê²ƒì„ ìœ ì§€ì‹œí‚¤ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ë§ê° ê²Œì´íŠ¸ì— ì˜í•´ ì¼ë¶€ ê¸°ì–µì„ ìƒê³ , ì…ë ¥ê²Œì´íŠ¸ì— ì˜í•´ ìœ ì§€ì‹œí‚¬ ê¸°ì–µì„ ì €ì¥í•œ ì…€ ìƒíƒœ $`C_t`$ê°€ ì¶”ê°€ë˜ì–´ ë‹¤ìŒ ë©”ëª¨ë¦¬ ì…€ë¡œ ì „íŒŒë©ë‹ˆë‹¤. 



í•´ë‹¹ ëª¨ë¸ì€ lstmì— classification ì„ ë¶™ì¸ ëª¨ë¸ì„.

lstmì„¤ëª… -> í† í¬ë‚˜ì´ì¦ˆ ë¶€ê°€ ì„¤ëª… -> activation ë° loss function ì„¤ëª…

í•™ìŠµë¨¸ì‹  : intel i7 12gen, ddr5 16GB

### total code
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
import torch
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
from torchtext.vocab import build_vocab_from_iterator
from torchtext.data.utils import get_tokenizer
import torch.nn as nn
import torch.optim as optim

# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
train_data = pd.read_csv('train.csv')
val_data = pd.read_csv('validation.csv')

# í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬
train_sentences = train_data['text'].values
train_labels = train_data['label'].values

# ê²€ì¦ ë°ì´í„° ì „ì²˜ë¦¬
val_sentences = val_data['text'].values
val_labels = val_data['label'].values

label_encoder = LabelEncoder()
train_labels = label_encoder.fit_transform(train_labels)
val_labels = label_encoder.transform(val_labels)

tokenizer = get_tokenizer("basic_english")

def yield_tokens(data_iter):
    for text in data_iter:
        yield tokenizer(text)

vocab = build_vocab_from_iterator(yield_tokens(train_sentences), specials=["<pad>", "<unk>"])
vocab.set_default_index(vocab["<unk>"])

class TextDataset(Dataset):
    def __init__(self, texts, labels, vocab, tokenizer):
        self.texts = texts
        self.labels = labels
        self.vocab = vocab
        self.tokenizer = tokenizer

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]
        tokens = self.tokenizer(text)
        token_ids = [self.vocab[token] for token in tokens]
        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)

def collate_batch(batch):
    text_list, label_list = [], []
    for _text, _label in batch:
        text_list.append(torch.tensor(_text, dtype=torch.long))
        label_list.append(torch.tensor(_label, dtype=torch.long))
    return pad_sequence(text_list, batch_first=True, padding_value=vocab["<pad>"]), torch.stack(label_list)

train_dataset = TextDataset(train_sentences, train_labels, vocab, tokenizer)
val_dataset = TextDataset(val_sentences, val_labels, vocab, tokenizer)

train_dataloader = DataLoader(train_dataset, batch_size='', shuffle=True, collate_fn=collate_batch)  # ë°°ì¹˜ì‚¬ì´ì¦ˆ ì¡°ì •
val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)

class LSTMClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim, lstm_units, num_classes, dropout_rate):
        super(LSTMClassifier, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab["<pad>"])
        self.lstm = nn.LSTM(embed_dim, lstm_units, num_layers = '', batch_first=True) # LSTM ë ˆì´ì–´ ìˆ˜ ì¡°ì •
        self.dropout = nn.Dropout(dropout_rate)
        self.fc = nn.Linear(lstm_units, num_classes)

    def forward(self, x):
        x = self.embedding(x)
        x, (hidden, _) = self.lstm(x)
        x = self.dropout(hidden[-1])
        x = self.fc(x)
        return x

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
embed_dim = ''
lstm_units = ''
dropout_rate = ''
learning_rate = ''
num_epochs = ''

# ëª¨ë¸ ì´ˆê¸°í™”
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = LSTMClassifier(vocab_size=len(vocab), embed_dim=embed_dim, lstm_units=lstm_units, num_classes=6, dropout_rate=dropout_rate).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# ì†ì‹¤ ê¸°ë¡ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
train_losses = []
val_losses = []

# ëª¨ë¸ í•™ìŠµ
model.train()
for epoch in range(num_epochs):
    train_loss = 0.0
    for texts, labels in train_dataloader:
        texts, labels = texts.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(texts)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    # ì—í¬í¬ë³„ í‰ê·  í›ˆë ¨ ì†ì‹¤ ê³„ì‚°
    train_loss /= len(train_dataloader)
    train_losses.append(train_loss)

    # ê²€ì¦ ë°ì´í„° ì†ì‹¤ ê³„ì‚°
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for texts, labels in val_dataloader:
            texts, labels = texts.to(device), labels.to(device)
            outputs = model(texts)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

    # ì—í¬í¬ë³„ í‰ê·  ê²€ì¦ ì†ì‹¤ ê³„ì‚°
    val_loss /= len(val_dataloader)
    val_losses.append(val_loss)

    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}')

# ì†ì‹¤ ì‹œê°í™”
plt.figure(figsize=(10, 6))
plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue')
plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss', color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Train and Validation Loss Over Epochs')
plt.legend()
plt.grid(True)
plt.show()

# ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
def evaluate_model(model, dataloader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for texts, labels in dataloader:
            texts, labels = texts.to(device), labels.to(device)
            outputs = model(texts)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = correct / total
    return accuracy

'''
# ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), 'model_weights.pth')
torch.save(model, 'model.pth')
'''

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
test_data = pd.read_csv('test.csv')
test_sentences = test_data['text'].values
test_labels = test_data['label'].values
test_labels = label_encoder.transform(test_labels)

test_dataset = TextDataset(test_sentences, test_labels, vocab, tokenizer)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€
test_accuracy = evaluate_model(model, test_dataloader)
print(f'Test Accuracy: {test_accuracy}')

```
## 2. BertForSequenceClassification
ìœ„ ëª¨ë¸ì€ Hugging Faceì˜ Transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‘ì—…ì„ ìœ„í•´ ì„¤ê³„ëœ BERT ê¸°ë°˜ ëª¨ë¸ì´ì´ë‹¤. ì´ ëª¨ë¸ì€ BERTì˜ ê¸°ë³¸ ì•„í‚¤í…ì³ ìœ„ì— ë¶„ë¥˜ë¥¼ ìœ„í•œ ì¶”ê°€ ë ˆì´ì–´ë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤.

ì „ì²´êµ¬ì¡°

![image](https://github.com/subineda01/HY-AI-x-DeepLearnig/assets/144909753/18a71006-4452-4258-93b4-3a8a0c0ff3ab)

ëª¨ë¸ì€ í¬ê²Œ ë‘ê°€ì§€ êµ¬ì¡°ì¸ BertModelê³¼ Classifierë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. BertModelì€ Transformer layerê°€ ì—¬ëŸ¬ê²¹ìœ¼ë¡œ ìŒ“ì—¬ìˆëŠ” ë³¸ì²´ì…ë‹ˆë‹¤. ì´ëŠ” BertEmbedding ë¶€ë¶„ê³¼ BertEncoderë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì ¸ ìˆë‹¤. 

### BertEmbedding

![image](https://github.com/subineda01/HY-AI-x-DeepLearnig/assets/144909753/589d2e7d-aeda-44d5-8a0c-9f73000fd8b6)

BertEmbeddingì€ ë¬¸ì¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ token, segment, positionì„ ì„ë² ë”©í•˜ì—¬ ê°’ìœ¼ë¡œ ë§Œë“¤ê³  ë”í•´ì„œ ë°˜í™˜í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.
1. í† í¬ë‚˜ì´ì§•(Tokenization):
   * ì…ë ¥ í…ìŠ¤íŠ¸ëŠ” WordPiece í† í¬ë‚˜ì´ì €ë¥¼ í†µí•´ í† í°ìœ¼ë¡œ ë¶„í•´ëœë‹¤.
   * í† í°ì€ ê³ ìœ í•œ ì •ìˆ˜ë¡œ ë§¤í•‘ëœë‹¤.
2. ì…ë ¥ ì„ë² ë”©(Input Embeddings):
   * Token Embedding : ê° í† í°ì— ëŒ€í•œ ê³ ìœ í•œ ì„ë² ë”© ë²¡í„°
   * Segment Embedding : ë¬¸ì¥ì´ ë‘ê°œì¼ ë•Œ ì²« ë¬¸ì¥ê³¼ ë‘ ë²ˆì§¸ ë¬¸ë‹¹ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ì„ë² ë”© ë²¡í„°
   * Position Embedding : ê° í† í°ì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„ë² ë”© ë²¡í„°. ë¬¸ì¥ ë‚´ì—ì„œ ê° í† í°ì˜ ìˆœì„œë¥¼ ëª¨ë¸ì´ ì•Œ ìˆ˜ ìˆê²Œ í•œë‹¤.

### BertEncoder

BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ëª¨ë¸ì˜ ì¸ì½”ë” ë¶€ë¶„ë§Œ ì‚¬ìš©í•œë‹¤.

#### íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë” ê°œìš”

BERTì˜ ì¸ì½”ë”ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë” ë¸”ë¡ì˜ ìŠ¤íƒìœ¼ë¡œ êµ¬ì„±ëœë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë”ëŠ” ì—¬ëŸ¬ ì¸µì˜ ì¸ì½”ë” ë¸”ë¡ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° ë¸”ë¡ì€ ë‹¤ìŒ ë‘ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.

1. Multi-Head Self-Attention Mechanism:
   - ê° í† í°ì´ ë‹¤ë¥¸ ëª¨ë“  í† í°ê³¼ì˜ ê´€ê³„(ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜)ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•œë‹¤.
   - ë‹¤ì–‘í•œ ì£¼ì˜(attention) í—¤ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë¡œ ë‹¤ë¥¸ ë¶€ë¶„ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë‹¤.

2. Position-wise Feed-Forward Neural Network:
   - Self-attentionì˜ ì¶œë ¥ì„ ê° í† í°ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì™„ì „ ì—°ê²° ë„¤íŠ¸ì›Œí¬
   - ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ í‘œí˜„ì„ í•™ìŠµ

#### BERT ì¸ì½”ë” êµ¬ì„± ìš”ì†Œ

##### Multi-Head Self-Attention

Multi-Head Self-Attention ë©”ì»¤ë‹ˆì¦˜ì€ ê° í† í°ì´ ë¬¸ì¥ì˜ ë‹¤ë¥¸ ëª¨ë“  í† í°ê³¼ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•œë‹¤.

- **Query, Key, Value ê³„ì‚°**: ì…ë ¥ ì„ë² ë”©ì„ ì„¸ ê°œì˜ í–‰ë ¬ \( W_Q \), \( W_K \), \( W_V \)ì— ê³±í•˜ì—¬ Query, Key, Value í–‰ë ¬ì„ ë§Œë“ ë‹¤.
  
   ![QKV Calculation](https://latex.codecogs.com/svg.latex?Q%20%3D%20XW_Q%2C%20%5Cquad%20K%20%3D%20XW_K%2C%20%5Cquad%20V%20%3D%20XW_V)

- **ì–´í…ì…˜ ì ìˆ˜ ê³„ì‚°**: Queryì™€ Keyì˜ ë‚´ì ì„ í†µí•´ ê° í† í° ìŒì˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ìŠ¤ì¼€ì¼ë§ í›„ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì–»ëŠ”ë‹¤.
  
   ![Attention Score](https://latex.codecogs.com/svg.latex?%5Ctext%7BAttention%7D(Q%2C%20K%2C%20V)%20%3D%20%5Ctext%7Bsoftmax%7D%5Cleft(%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%5Cright)V)

- **Multi-Head Attention**: ì—¬ëŸ¬ ê°œì˜ ì–´í…ì…˜ í—¤ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ê° í—¤ë“œì˜ ì¶œë ¥ì„ ê²°í•©
  
   ![Multi-Head Attention](https://latex.codecogs.com/svg.latex?%5Ctext%7BMultiHead%7D(Q%2C%20K%2C%20V)%20%3D%20%5Ctext%7BConcat%7D(%5Ctext%7Bhead%7D_1%2C%20%5Cldots%2C%20%5Ctext%7Bhead%7D_h)W_O)

### Position-wise Feed-Forward Neural Network

ê° í† í°ì— ëŒ€í•´ ë…ë¦½ì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ë‘ ê°œì˜ ì„ í˜• ë³€í™˜ê³¼ ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ë¡œ êµ¬ì„±ëœ ì™„ì „ ì—°ê²° ì‹ ê²½ë§

![Feed-Forward Neural Network](https://latex.codecogs.com/svg.latex?%5Ctext%7BFFN%7D(x)%20%3D%20%5Ctext%7Bmax%7D(0%2C%20xW_1%20%2B%20b_1)W_2%20%2B%20b_2)

### ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™” (Residual Connections and Layer Normalization)

ê° íŠ¸ëœìŠ¤í¬ë¨¸ ì¸ì½”ë” ë¸”ë¡ì€ ë‘ ê°œì˜ ì„œë¸Œë ˆì´ì–´(Sublayer)ë¡œ êµ¬ì„±:

1. **Self-Attention Sublayer**: Multi-Head Self-Attentionì„ ì ìš©
2. **Feed-Forward Sublayer**: Position-wise Feed-Forward Neural Networkë¥¼ ì ìš©

ê° ì„œë¸Œë ˆì´ì–´ í›„ì—ëŠ” ì”ì°¨ ì—°ê²°ê³¼ ì¸µ ì •ê·œí™”ë¥¼ ì ìš©í•˜ì—¬ í•™ìŠµì„ ì•ˆì •í™”í•˜ê³  ì„±ëŠ¥ì„ í–¥ìƒ

# IV. Evaluation & Result
### Word Cloud
![wordcloud](https://github.com/subineda01/HY-AI-x-DeepLearnig/assets/144909753/7c09d6b2-6d35-499e-829f-e3a0c45c03dc)

### Loss Graph

![losses](https://github.com/subineda01/HY-AI-x-DeepLearnig/assets/144909753/f59b3c2c-3543-4fa6-b6e5-db7cfd8b9b79)

### Confusion Matrix
![confusion_matrix](https://github.com/subineda01/HY-AI-x-DeepLearnig/assets/144909753/c118b4a3-fb0e-40ca-be83-a38c75df86da)

### Result

![image](https://github.com/subineda01/HY-AI-x-DeepLearnig/assets/144909753/cd90b260-6261-4686-971f-1b6c57635c0b)
ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ê³  ì‹¤í—˜ì„ í•´ë³´ì•˜ìŒ. í•™ìŠµë¥ ì„ 2e-3 2e-4 2e-r-5ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ í•´ë³¸ ê²°ê³¼ 2e-5ì¼ ë•Œì˜ ì„±ëŠ¥ì´ ì œì¼ ë‚˜ì•˜ìŒ. ì—í¬í¬ ìˆ˜ëŠ”  5 10 30ì„ ê°€ì§€ê³  ì‹¤í—˜ í•´ë³¸ ê²°ê³¼ ì—í¬í¬ ìˆ˜ê°€ ì»¤ì§€ë©´ ì»¤ì§ˆìˆ˜ë¡ validation lossê°€ ì»¤ì§ì„ í™•ì¸ í•  ìˆ˜ ìˆì—ˆìŒ. ë”°ë¼ì„œ ì—í¬í¬ ìˆ˜ëŠ” 5ë¡œ ì„¤ì •í•˜ì˜€ìŒ. ë§ˆì§€ë§‰ìœ¼ë¡œ ë°°ì¹˜ ìˆ˜ë¥¼ 16 32 64ë¡œ ë³€ê²½í•´ ë³´ì•˜ì§€ë§Œ í° ì°¨ì´ëŠ” ì—†ì—ˆìŒ. ê²°ê³¼ì ìœ¼ë¡œ ì •í™•ë„ì™€ ì¬í˜„ìœ¨ì´ ëª¨ë‘ 93%ëŒ€ë¥¼ ê¸°ë¡í•˜ì˜€ìŒ

# V. Conclusion: Discussion

ê°ì •ì„ í…ìŠ¤íŠ¸ë¡œë¶€í„° ì¸ì‹í•˜ëŠ” ë° ìˆì–´ ê¸°ì¡´ ë°©ë²•ë“¤ì„ ë›°ì–´ë„˜ëŠ” ìƒˆë¡œìš´ ê·¸ë˜í”„ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì„ ì„ ë³´ì¸ë‹¤. ì´ ì•Œê³ ë¦¬ì¦˜ì€ ê°ì •ì´ í‘œí˜„ë˜ëŠ” ë‹¤ì–‘í•œ ì–¸ì–´ì  ë‰˜ì•™ìŠ¤ë¥¼ í¬ì°©í•˜ê³  ëª¨ë¸ë§í•˜ê¸° ìœ„í•´ í’ë¶€í•œ êµ¬ì¡°ì  ì„¤ëª…ìë¥¼ ìƒì„±í•œë‹¤. ì œì•ˆëœ ë°©ë²•ì€ ë‹¨ì–´ ì„ë² ë”©ì„ í†µí•´ ë”ìš± í’ë¶€í•´ì§„ íŒ¨í„´ ê¸°ë°˜ í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ ê°ì • ì¸ì‹ ì‘ì—…ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì˜€ì¤€ë‹¤.

ìœ„ ëª¨ë¸ì„ í†µí•œ ìƒˆë¡œìš´ ê¸°ìˆ 

ì •ì‹  ê±´ê°• ê´€ë¦¬ ì‹œìŠ¤í…œì˜ í˜ì‹ 
ì¡°ê¸° ê²½ê³  ì‹œìŠ¤í…œ: ì†Œì…œ ë¯¸ë””ì–´ì™€ ì˜¨ë¼ì¸ í™œë™ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ìš°ìš¸ì¦, ë¶ˆì•ˆ ë“±ì˜ ì •ì‹  ê±´ê°• ë¬¸ì œë¥¼ ì¡°ê¸°ì— ê²½ê³ í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì„ ê°œë°œí•  ìˆ˜ ìˆë‹¤.
ê°œì¸ ë§ì¶¤í˜• ì¹˜ë£Œ ê³„íš: ê°ì • ì¸ì‹ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸ ë§ì¶¤í˜• ì¹˜ë£Œ ê³„íšì„ ì„¸ìš°ê³ , ì •ê¸°ì ìœ¼ë¡œ í™˜ìì˜ ê°ì • ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ì¹˜ë£Œì˜ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆë‹¤.

ê³ ê° ì„œë¹„ìŠ¤ ë° ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ
ì‹¤ì‹œê°„ ê°ì • ë¶„ì„: ê³ ê°ì˜ ê°ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì¦‰ê°ì ì¸ ëŒ€ì‘ì„ í†µí•´ ê³ ê° ë§Œì¡±ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤.
ê°œì¸í™”ëœ ì„œë¹„ìŠ¤ ì œê³µ: ê³ ê°ì˜ ê°ì • ìƒíƒœì— ê¸°ë°˜í•œ ë§ì¶¤í˜• ì„œë¹„ìŠ¤ ì œê³µìœ¼ë¡œ ê³ ê° ì¶©ì„±ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆë‹¤.

ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš© ê°œì„ 
ê°ì • ë°˜ì‘ AI ë¹„ì„œ: ê°ì •ì„ ì´í•´í•˜ê³  ë°˜ì‘í•˜ëŠ” AI ë¹„ì„œë‚˜ ë¡œë´‡ì„ ê°œë°œí•˜ì—¬ ì‚¬ìš©ìì™€ì˜ ìƒí˜¸ì‘ìš©ì„ ë”ìš± ìì—°ìŠ¤ëŸ½ê³  ì¸ê°„ì ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.
êµìœ¡ ë° ì—”í„°í…Œì¸ë¨¼íŠ¸ ë¶„ì•¼: ê°ì •ì„ ì´í•´í•˜ëŠ” êµìœ¡ìš© ë¡œë´‡ì´ë‚˜ ì—”í„°í…Œì¸ë¨¼íŠ¸ ì‹œìŠ¤í…œì„ í†µí•´ í•™ìŠµ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ê³  ì‚¬ìš©ì ê²½í—˜ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.

ì‚¬íšŒì  ë¬¸ì œ í•´ê²°
ì‚¬ì´ë²„ ë¶ˆë§ ë° í˜ì˜¤ ë°œì–¸ ê°ì§€: ì†Œì…œ ë¯¸ë””ì–´ì—ì„œ ì‚¬ì´ë²„ ë¶ˆë§ì´ë‚˜ í˜ì˜¤ ë°œì–¸ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì‚¬ì „ ì˜ˆë°© ì¡°ì¹˜ë¥¼ ì·¨í•  ìˆ˜ ìˆë‹¤.
ì‚¬íšŒì  íŠ¸ë Œë“œ ë¶„ì„: ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬íšŒì  íŠ¸ë Œë“œì™€ ê°ì • ë³€í™”ë¥¼ íŒŒì•…í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íš¨ê³¼ì ì¸ ì •ì±… ìˆ˜ë¦½ì„ ì§€ì›í•  ìˆ˜ ìˆë‹¤.

ìƒìš©í™” ë° ì„±ê³µ ê°€ëŠ¥ì„±
ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê°ì • ì¸ì‹ ê¸°ìˆ ì€ ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ë¡œ ìƒìš©í™”ì™€ ì„±ê³µ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.

ë‹¤ì–‘í•œ ì ìš© ë¶„ì•¼: ì •ì‹  ê±´ê°•, ê³ ê° ì„œë¹„ìŠ¤, HCI, ì‚¬íšŒì  ë¬¸ì œ í•´ê²° ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš© ê°€ëŠ¥ì„±ì´ ë†’ì•„ ì‹œì¥ ìˆ˜ìš”ê°€ í¬ë‹¤.
ê¸°ìˆ ì˜ ì •ë°€ë„ ë° ì‹ ë¢°ì„±: CARER ì•Œê³ ë¦¬ì¦˜ì˜ ë†’ì€ ì •í™•ë„ì™€ ì‹ ë¢°ì„±ìœ¼ë¡œ ì¸í•´ ì‹¤ì§ˆì ì¸ ë¬¸ì œ í•´ê²°ì— ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤.
ê¸°ìˆ ì˜ ìœ ì—°ì„±: ì´ ê¸°ìˆ ì€ ì—¬ëŸ¬ ì–¸ì–´ì™€ ë¬¸í™”ì  ë§¥ë½ì—ì„œë„ ì ìš© ê°€ëŠ¥í•˜ì—¬ ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œë„ í™œìš©ë  ìˆ˜ ìˆë‹¤.
ì§€ì†ì ì¸ ë°œì „ ê°€ëŠ¥ì„±: ë”¥ëŸ¬ë‹ê³¼ ê·¸ë˜í”„ ê¸°ë°˜ ë°©ë²•ì˜ ë°œì „ìœ¼ë¡œ ê¸°ìˆ ì´ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë  ìˆ˜ ìˆì–´ ì¥ê¸°ì ì¸ ì„±ì¥ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.

ë”¥ëŸ¬ë‹ ê¸°ë°˜ ê°ì • ì¸ì‹ ê¸°ìˆ ì€ ì—¬ëŸ¬ ì‚°ì—… ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆë‹¤. ì´ ê¸°ìˆ ì€ ì •ì‹  ê±´ê°• ê´€ë¦¬, ê³ ê° ì„œë¹„ìŠ¤, ì¸ê°„-ì»´í“¨í„° ìƒí˜¸ì‘ìš©, ì‚¬íšŒì  ë¬¸ì œ í•´ê²° ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‹¤ì§ˆì ì¸ ë³€í™”ë¥¼ ì´ëŒì–´ë‚¼ ìˆ˜ ìˆë‹¤. ë˜í•œ, ìƒìš©í™” ê°€ëŠ¥ì„±ì´ ë†’ê³ , ë‹¤ì–‘í•œ ìƒˆë¡œìš´ ê¸°ìˆ ë¡œ ë°œì „í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ í¬ë‹¤. ì•ìœ¼ë¡œë„ ì§€ì†ì ì¸ ì—°êµ¬ì™€ ë°œì „ì„ í†µí•´ ì¸ë¥˜ì˜ ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¤ê³ , ë” ë‚˜ì€ ì‚¬íšŒë¥¼ ë§Œë“œëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•  ê²ƒì´ë‹¤.

# VI. Related Works & References

íˆ´(Tool): 

ë¼ì´ë¸ŒëŸ¬ë¦¬(Library): 

### ë¸”ë¡œê·¸(Blog)
### ë…¼ë¬¸
[Contextualized Affect Representations for Emotion Recognition](https://aclanthology.org/D18-1404.pdf)





