{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "sentences = data['text'].values\n",
        "labels = data['label'].values\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "X_train, X_val, y_train, y_val = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(X_train), specials=[\"<pad>\", \"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        tokens = self.tokenizer(text)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    text_list, label_list = [], []\n",
        "    for _text, _label in batch:\n",
        "        text_list.append(torch.tensor(_text, dtype=torch.long))\n",
        "        label_list.append(torch.tensor(_label, dtype=torch.long))\n",
        "    return pad_sequence(text_list, batch_first=True, padding_value=vocab[\"<pad>\"]), torch.stack(label_list)\n",
        "\n",
        "train_dataset = TextDataset(X_train, y_train, vocab, tokenizer)\n",
        "val_dataset = TextDataset(X_val, y_val, vocab, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, lstm_units, num_classes, dropout_rate):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab[\"<pad>\"])\n",
        "        self.lstm = nn.LSTM(embed_dim, lstm_units, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(lstm_units, num_classes)  # Fully Connected Layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # x는 (batch_size, seq_length, embed_dim) 크기의 텐서\n",
        "        x, (hidden, _) = self.lstm(x)  # hidden은 (1, batch_size, lstm_units) 크기의 텐서\n",
        "        x = self.dropout(hidden[-1])  # hidden[-1]은 (batch_size, lstm_units) 크기의 텐서\n",
        "        x = self.fc(x)  # x는 (batch_size, num_classes) 크기의 텐서\n",
        "        return x\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "embed_dim = 128\n",
        "lstm_units = 128\n",
        "dropout_rate = 0.3\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 10\n",
        "\n",
        "# 모델 초기화\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMClassifier(vocab_size=len(vocab), embed_dim=embed_dim, lstm_units=lstm_units, num_classes=6, dropout_rate=dropout_rate).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 모델 학습\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for texts, labels in train_dataloader:\n",
        "        texts, labels = texts.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# 모델 평가 함수\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in dataloader:\n",
        "            texts, labels = texts.to(device), labels.to(device)\n",
        "            outputs = model(texts)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# 검증 데이터로 모델 평가\n",
        "val_accuracy = evaluate_model(model, val_dataloader)\n",
        "print(f'Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'model_weights.pth')\n",
        "torch.save(model, 'model.pth')\n",
        "\n",
        "# 테스트 데이터 로드 및 전처리\n",
        "test_data = pd.read_csv('/content/test.csv')\n",
        "test_sentences = test_data['text'].values\n",
        "test_labels = test_data['label'].values\n",
        "test_labels = label_encoder.transform(test_labels)\n",
        "test_dataset = TextDataset(test_sentences, test_labels, vocab, tokenizer)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "# 테스트 데이터로 모델 평가\n",
        "test_accuracy = evaluate_model(model, test_dataloader)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SprqN-Bd7JbB",
        "outputId": "d4be9aca-29d5-4633-b224-47062ed0383b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e15e34eb5228>:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  text_list.append(torch.tensor(_text, dtype=torch.long))\n",
            "<ipython-input-10-e15e34eb5228>:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label_list.append(torch.tensor(_label, dtype=torch.long))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.6563297510147095\n",
            "Epoch 2/10, Loss: 1.6158767938613892\n",
            "Epoch 3/10, Loss: 1.5254058837890625\n",
            "Epoch 4/10, Loss: 1.4879822731018066\n",
            "Epoch 5/10, Loss: 1.515523076057434\n",
            "Epoch 6/10, Loss: 1.6789978742599487\n",
            "Epoch 7/10, Loss: 1.3882092237472534\n",
            "Epoch 8/10, Loss: 0.8263146281242371\n",
            "Epoch 9/10, Loss: 0.6810016632080078\n",
            "Epoch 10/10, Loss: 0.4650488495826721\n",
            "Validation Accuracy: 0.6715625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-e15e34eb5228>:49: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  text_list.append(torch.tensor(_text, dtype=torch.long))\n",
            "<ipython-input-10-e15e34eb5228>:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  label_list.append(torch.tensor(_label, dtype=torch.long))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, vocab, tokenizer):\n",
        "    tokens = tokenizer(text)\n",
        "    token_ids = [vocab[token] for token in tokens]\n",
        "    return torch.tensor(token_ids, dtype=torch.long).unsqueeze(0)  # 배치 차원을 추가합니다.\n",
        "\n",
        "def predict_sentence(model, text, vocab, tokenizer):\n",
        "    model.eval()\n",
        "    input_tensor = preprocess_text(text, vocab, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "    predicted_class = torch.argmax(output, dim=1).item()\n",
        "    return predicted_class\n",
        "\n",
        "# 예시 문장\n",
        "example_sentence = \"I am so scared of ghosts. I will never go there again.\"\n",
        "\n",
        "# 예측\n",
        "predicted_class = predict_sentence(model, example_sentence, vocab, tokenizer)\n",
        "print(f'The predicted class for the input sentence is: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBw1-KEF_23U",
        "outputId": "1a3b7f3c-4c4d-47ac-b55c-d7c4b934e31e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class for the input sentence is: 4\n"
          ]
        }
      ]
    }
  ]
}